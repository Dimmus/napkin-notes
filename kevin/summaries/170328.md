## Best Docs to Date
- [API usage overview](https://github.com/openstax/napkin-notes/blob/master/kevin/160921_biglearnApis/api_usage.md)
- [BL deployment overview](https://github.com/openstax/napkin-notes/blob/master/kevin/BiglearnArchitectureDeployment.pdf)
- [Drew's presentation](https://docs.google.com/presentation/d/1qoPqBLD4XqOsIfcM6aJH7IaDQRsxxuA6QBLy4GIZy7w/edit#slide=id.p)
- [Kevin's SPARFA Guide](https://github.com/openstax/sparfa-sandbox/blob/klb_sgd/klb_sparfa_guide/sparfa_guide.pdf)

## SGD-based SPARFA

### Effect of Allowing SPARFA to Learn

The following plot shows the effects
of L1 and L2 regularizer penalties
(which control how much SPARFA is allowed to learn from data
versus sticking with the given concept hints)
on imputation performance.
Cost function 1 (CF1) has modest penalties,
whereas cost function 2 (CF2) has larger penalties.
Peak imputation accuracy imporoves by ~1%
when SPARFA is allowed to learn from the data:

<img src="https://github.com/openstax/napkin-notes/blob/master/kevin/summaries/CF_LearningComp.png" alt="learning effects" width="300" height="300">
